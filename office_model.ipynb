{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/'\n",
    "train_df = pd.read_csv(root + 'train.csv')\n",
    "train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "weather_train_df = pd.read_csv(root + 'weather_train.csv')\n",
    "weather_train_df[\"timestamp\"] = pd.to_datetime(weather_train_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# test_df = pd.read_csv(root + 'test.csv')\n",
    "# test_df[\"hour\"] = pd.to_datetime(test_df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S').dt.hour\n",
    "\n",
    "# weather_test_df = pd.read_csv(root + 'weather_test.csv')\n",
    "building_meta_df = pd.read_csv(root + 'building_metadata.csv')\n",
    "sample_submission = pd.read_csv(root + 'sample_submission.csv')\n",
    "\n",
    "weather_test_df = pd.read_csv(root + 'weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test_df = reduce_mem_usage(weather_test_df)\n",
    "weather_test_df.isnull().sum() / len(weather_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(train_df)\n",
    "weather_train_df = reduce_mem_usage(weather_train_df)\n",
    "building_meta_df = reduce_mem_usage(building_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df.isnull().sum() / len(weather_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us select only office buildings with meter 0 measurements\n",
    "b_data = pd.merge(train_df, building_meta_df, on='building_id')\n",
    "b_0 = b_data.query('meter==0')\n",
    "print(\"rows:\", len(b_0))\n",
    "b_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us add weather\n",
    "\n",
    "# let us merge it with weather for this site\n",
    "b = b_0.drop(columns=['meter', 'primary_use', 'year_built', 'floor_count'])\n",
    "b = pd.merge(b, weather_train_df, on=['site_id','timestamp'])\n",
    "b['timestamp'] = pd.to_datetime(b[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "print(\"records:\", len(b))\n",
    "\n",
    "b = b.drop(columns=['cloud_coverage', 'precip_depth_1_hr', 'sea_level_pressure', \n",
    "                    'wind_direction', 'wind_speed'])\n",
    "                    \n",
    "b = b.dropna()\n",
    "print(\"records after dropping NaN:\", len(b))\n",
    "\n",
    "# b = b[b['square_feet'] > 0]\n",
    "b['Y'] = b['meter_reading'] / b['square_feet']\n",
    "b['workhour'] = np.abs(b['timestamp'].dt.hour - 12) < 5.5\n",
    "b['workday'] = b['timestamp'].dt.weekday < 5\n",
    "\n",
    "print(\"rows in dataset:\", len(b))\n",
    "# b = b.query('timestamp == \"2016-03-12 14:00:00\"')\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero values for meter_readings looks abnormally\n",
    "\n",
    "bld = b.drop(columns=['meter_reading', 'site_id', 'timestamp', 'square_feet'])\n",
    "bld = bld.astype({'building_id':int, 'workhour': int, 'workday': int})\n",
    "bld.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bld.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_id_to_vec(b_id):\n",
    "    vec = np.zeros(1449)\n",
    "    vec[int(b_id)] = 1\n",
    "    return vec\n",
    "\n",
    "def to_XY(matrix):\n",
    "    X = np.zeros((len(matrix), 1453))\n",
    "    Y = np.zeros(len(matrix))\n",
    "    for i in range(len(matrix)):\n",
    "        b, t1, t2, y, h, d = matrix[i]\n",
    "        X[i] = np.hstack([b_id_to_vec(b), t1/50, t2/50, h, d])\n",
    "        Y[i] = y\n",
    "    return (X,Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = to_XY(bld.values[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_15 = b[b.building_id==15]\n",
    "b_15.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = b_15[['air_temperature', 'dew_temperature', 'workhour', 'workday']].values\n",
    "y = 1000*b_15['Y'].values\n",
    "plt.scatter(X[:,0],y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes=(6,), learning_rate_init=0.02, alpha=0.05,\n",
    "                 learning_rate='adaptive')\n",
    "nn.fit(X,y)\n",
    "nn.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nn.predict(X)\n",
    "plt.scatter(X[:,0],g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
